{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yeah this file is a lot cleaner than the first one\n",
    "# more things work here\n",
    "# and it's a lot better organized\n",
    "import re\n",
    "import simdjson as sj\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import swifter\n",
    "import seaborn as sns\n",
    "import numpy as np\t\n",
    "from nltk import sent_tokenize\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from wutils.general import save_pickle, load_pickle\n",
    "from wutils.mat import MarkedMatrix\n",
    "from scipy.spatial.distance import cdist\n",
    "# for kernel\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from treeinterpreter import treeinterpreter as ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed from ./pickles/who_cord_df.pkl to ./pickles/newest_cord_df_ft.pkl\n",
    "cord_df = load_pickle('./pickles/newest_cord_df_ft.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed from ./pickles/newest_good_sample_df_ft.pkl to clean_good_df.pkl\n",
    "good_df = load_pickle('./pickles/clean_good_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed from ./pickles/newest_bad_df_ft.pkl to cleab_bad_df.pkl\n",
    "bad_df = load_pickle('./pickles/clean_bad_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# he's looking for a specific document here\n",
    "# to show an example of clean text\n",
    "good_df[good_df.cleanText.swifter.apply(lambda x: 'Virus-ridden particles are inhaled by others and come into contact with cells' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some function to parse urls\n",
    "import urllib.parse\n",
    "\n",
    "def get_hostname(url):\n",
    "    o = urllib.parse.urlsplit(url)\n",
    "    return o.hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guess he only wants news related to wuhan\n",
    "# showing an example of how to filter text\n",
    "def news_filter(text):\n",
    "    keep_if = ['wuhan']\n",
    "    text = text.lower()\n",
    "    blacklist = ['u.s.', 'america', 'korea', 'china', 'mexico', 'australia', 'uk', 'u.k.', 'new york', 'los angeles', 'nfl', 'nba', 'mlb', 'epl']\n",
    "    if any(x in text for x in keep_if):\n",
    "        return True\n",
    "    if any(x in text for x in blacklist):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these next few cells, I'm assuming he's just intializing the dataframes to be used\n",
    "# I have no idea how some of this works\n",
    "# and I don't really want to find out\n",
    "# I am just going to trust that this works and that we will get functional data after all this is done\n",
    "# good work Will!\n",
    "good_df['hostname'] = good_df['url'].swifter.apply(get_hostname)\n",
    "bad_df['hostname'] = bad_df['url'].swifter.apply(get_hostname)\n",
    "good_df['mean_embed'] = good_df['sent_embeddings'].swifter.apply(lambda x: x.mean(axis=0))\n",
    "bad_df['mean_embed'] = bad_df['sent_embeddings'].swifter.apply(lambda x: x.mean(axis=0))\n",
    "\n",
    "is_AP = bad_df['cleanText'].swifter.apply(lambda x: '(AP)' in x)\n",
    "print('Found: ', is_AP.sum())\n",
    "bad_df = bad_df[~is_AP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KW = 'transmission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cord_df = cord_df.dropna()\n",
    "cord_df['mean_embed'] = cord_df['sent_embeddings'].swifter.apply(lambda x: x.mean(axis=0))\n",
    "# this right here is simply filtering out to find the word vaccine\n",
    "has_vax = cord_df[cord_df.title.swifter.apply(lambda x: KW in x.lower()) | cord_df.abstract.swifter.apply(lambda x: KW in x.lower())]\n",
    "# vax_ref gets used quite a bit later, I assume he is first filtering out data from cord that contains\n",
    "# information relevant to vaccines\n",
    "# from the paper:\n",
    "# \"We extract a filtered set, which has articles with sports teams and popular cities/countries removed,\n",
    "# and refer to it as the “Filtered News” dataset\n",
    "# We also extract only articles that contain the word “vaccine” and call this the “Vaccine News” dataset\"\n",
    "vax_ref = np.vstack(has_vax['mean_embed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vax_good_df = good_df[good_df['cleanText'].swifter.apply(lambda x: KW in x.lower())]\n",
    "# vax_bad_df = bad_df[bad_df['cleanText'].swifter.apply(lambda x: KW in x.lower())]\n",
    "vax_good_df = good_df\n",
    "vax_bad_df = bad_df\n",
    "vax_good_df = vax_good_df[vax_good_df['cleanText'].swifter.apply(news_filter)]\n",
    "vax_bad_df = vax_bad_df[vax_bad_df['cleanText'].swifter.apply(news_filter)]\n",
    "vax_good_mat = np.vstack(vax_good_df.mean_embed)\n",
    "vax_bad_mat = np.vstack(vax_bad_df.mean_embed)\n",
    "vax_raw_mm = MarkedMatrix([('good', vax_good_mat), ('bad', vax_bad_mat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# he's calculating distances between reference dataframe and to-be-labeled dataframe here I am assuming \n",
    "# below is a link to possible other metrics to use besides cosine\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html\n",
    "# so, vgood2ref is the distance between vax_good_mat and vax_ref\n",
    "vgood2ref = cdist(vax_good_mat, vax_ref, 'cosine')\n",
    "print('done w/ good')\n",
    "# vbad2ref is the distance between vax_bad_mat and vax_ref\n",
    "vbad2ref = cdist(vax_bad_mat, vax_ref, 'cosine')\n",
    "print('done w/ bad')\n",
    "vax_mm = MarkedMatrix([('good', vgood2ref), ('bad', vbad2ref)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# none of the stuff written below here needs to be re-run when changing the distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alt method\n",
    "# has_vax = cord_df.sample(5000)\n",
    "# vax_ref = np.vstack(has_vax['mean_embed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# War on Terror Cells: Strategies to Eradicate \"Novel Coronavirus\" Effectively\n",
    "np.where(~np.isfinite(vax_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest: a collection of decision trees, where the final decision is the average of all the trees\n",
    "# the idea is: the crowd is smarter\n",
    "raw_tmodel = RandomForestClassifier(n_estimators=500, n_jobs=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmodel = RandomForestClassifier(n_estimators=500, n_jobs=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmodel 2 is just a fatter randomForestClassified\n",
    "# should work better supposedly?\n",
    "tmodel2 = RandomForestClassifier(n_estimators=1500, n_jobs=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidx = 263\n",
    "# he's finding the clean text for vax_good here\n",
    "# not sure exactly what cleanText means but\n",
    "vax_good_df.iloc[tidx].title, vax_good_df.iloc[tidx].cleanText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moved this function here from below\n",
    "# commented out where it originally was\n",
    "def tree_explain_good(idx):\n",
    "    pred, bias, contrib = ti.predict(tmodel, vgood2ref[idx, :].reshape((1, -1)))\n",
    "    print('CLEAN TEXT: ', vax_good_df.iloc[idx].cleanText)\n",
    "    cmat = contrib.reshape((-1, 2))\n",
    "    print('Prediction: ', pred)\n",
    "    print('Bias: ', bias)\n",
    "    import_bad = np.argsort(cmat[:, 0])[::-1]\n",
    "    import_good = np.argsort(cmat[:, 1])[::-1]\n",
    "    print('===== Towards Good: =====')\n",
    "    for idx in import_good[:5]:\n",
    "        print('-'*45)\n",
    "        print(f'CONTRIB: {cmat[idx]}')\n",
    "        print(f'ABSTRACT: {has_vax.iloc[idx].abstract}')\n",
    "        print(f'TITLE: {has_vax.iloc[idx].title}')\n",
    "    print('===== Towards Bad: =====')\n",
    "    for idx in import_bad[:5]:\n",
    "        print('-'*45)\n",
    "        print(f'CONTRIB: {cmat[idx]}')\n",
    "        print(f'ABSTRACT: {has_vax.iloc[idx].abstract}')\n",
    "        print(f'TITLE: {has_vax.iloc[idx].title}')\n",
    "\n",
    "def tree_explain_bad(idx):\n",
    "    pred, bias, contrib = ti.predict(tmodel, vbad2ref[idx, :].reshape((1, -1)))\n",
    "    print('CLEAN TEXT: ', vax_bad_df.iloc[idx].cleanText)\n",
    "    cmat = contrib.reshape((-1, 2))\n",
    "    print('Prediction: ', pred)\n",
    "    print('Bias: ', bias)\n",
    "    import_bad = np.argsort(cmat[:, 0])[::-1]\n",
    "    import_good = np.argsort(cmat[:, 1])[::-1]\n",
    "    print('===== Towards Bad: =====')\n",
    "    for idx in import_bad[:5]:\n",
    "        print('-'*45)\n",
    "        print(f'CONTRIB: {cmat[idx]}')\n",
    "        print(f'ABSTRACT: {has_vax.iloc[idx].abstract}')\n",
    "        print(f'TITLE: {has_vax.iloc[idx].title}')\n",
    "    print('===== Towards Good: =====')\n",
    "    for idx in import_good[:5]:\n",
    "        print('-'*45)\n",
    "        print(f'CONTRIB: {cmat[idx]}')\n",
    "        print(f'ABSTRACT: {has_vax.iloc[idx].abstract}')\n",
    "        print(f'TITLE: {has_vax.iloc[idx].title}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the hell is this function defined??\n",
    "# ok, I'm getting this weird error here:\n",
    "# AttributeError: 'RandomForestClassifier' object has no attribute 'n_outputs_'\n",
    "# maybe something needs to be run first before this is run?\n",
    "# man, I fucked up though\n",
    "# I ran this without noting the cell number, so I have no idea when this was run before\n",
    "# I will come back to this after I run some other stuff and see if it works\n",
    "# tree_explain_good(250)\n",
    "# going to move this below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vax_mm.mat[~np.isfinite(vax_mm.mat)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think here is where he starts evaluating how good the model functions\n",
    "# I guess closer to 1 is good, and closer to 0 is bad?\n",
    "# if I change the difference calculations above, maybe these numbers will change\n",
    "\n",
    "# also: vax_mm was defined above as a marked matrix of vgood2ref as good, and vbad2ref as bad\n",
    "# with vgood2ref as the distance between the good matrix and the vax ref\n",
    "# and with vbad2ref as the distance between the bad matrix and the vax ref\n",
    "# ideally, vgood2ref should have small distances\n",
    "# while vbad2ref whould hav elarge distances\n",
    "# I'm not sure how this works out number wise, but I'll have to think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== RUN FIRST TIME WITH COSINE ======\n",
    "cosineResults = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('trial_1:')\n",
    "start = time.time()\n",
    "res = vax_mm.single_split_classify(tmodel, return_labels=True)\n",
    "print(res)\n",
    "cosineResults['trial_1'] = res\n",
    "end = time.time()\n",
    "print('seconds: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running vax_mm with tmodel again\n",
    "print('trial_2:')\n",
    "start = time.time()\n",
    "res = vax_mm.single_split_classify(tmodel, return_labels=True)\n",
    "print(res)\n",
    "cosineResults['trial_2'] = res\n",
    "end = time.time()\n",
    "print('seconds: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running vax_raw_mm with raw_t_model\n",
    "print('trial_3:')\n",
    "start = time.time()\n",
    "res = vax_raw_mm.single_split_classify(raw_tmodel, return_labels=True)\n",
    "print(res)\n",
    "cosineResults['trial_3'] = res\n",
    "end = time.time()\n",
    "print('seconds: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running vax_mm with tmodel2\n",
    "print('trial_4:')\n",
    "start = time.time()\n",
    "res = vax_mm.single_split_classify(tmodel2, return_labels=True)\n",
    "print(res)\n",
    "cosineResults['trial_4'] = res\n",
    "end = time.time()\n",
    "print('seconds: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running vax_raw_mm with tmodel2\n",
    "print('trial_5:')\n",
    "start = time.time()\n",
    "res = vax_raw_mm.single_split_classify(tmodel2, return_labels=True)\n",
    "print(res)\n",
    "cosineResults['trial_5'] = res\n",
    "end = time.time()\n",
    "print('seconds: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the contents of cosineResults\n",
    "for e in cosineResults:\n",
    "    print('===================')\n",
    "    print(e)\n",
    "    print(cosineResults[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok here, we want to change from a simple distance calculation into a kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgood2ref = pairwise_kernels(vax_good_mat, vax_ref, metric='polynomial')\n",
    "print('done w/ good')\n",
    "vbad2ref = pairwise_kernels(vax_bad_mat, vax_ref, metric='polynomial')\n",
    "print('done w/ bad')\n",
    "vax_mm = MarkedMatrix([('good', vgood2ref), ('bad', vbad2ref)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old distance calculation for reference\n",
    "# so as of right now, vgood2ref and vbad2ref are a set of distances of each article from the reference articles\n",
    "# and this distance is use to classify\n",
    "# if we convert to kernels, we would need to convert positions into an array of numbers somehow\n",
    "# can kernels do that?\n",
    "# stay tuned to find out!\n",
    "\n",
    "# vgood2ref = cdist(vax_good_mat, vax_ref, 'cosine')\n",
    "# print('done w/ good')\n",
    "# # vbad2ref is the distance between vax_bad_mat and vax_ref\n",
    "# vbad2ref = cdist(vax_bad_mat, vax_ref, 'cosine')\n",
    "# print('done w/ bad')\n",
    "# vax_mm = MarkedMatrix([('good', vgood2ref), ('bad', vbad2ref)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok so this works if we put it here I guess\n",
    "tree_explain_good(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so it seems that tree_explain_good works after all the training is done\n",
    "tree_explain_good(107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tree_explain_good(43)\n",
    "tree_explain_good(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tree_explain_good(43)\n",
    "tree_explain_good(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this hasn't been run before\n",
    "# changing t-model to have fewer estimators\n",
    "tmodel2 = RandomForestClassifier(n_estimators=500, n_jobs=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neither has this\n",
    "# nothing below this has been run before\n",
    "# train and evaluate\n",
    "# vax_raw_mm with tmodel2\n",
    "vax_raw_mm.single_split_classify(tmodel2, return_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok so tree_explain is defined all the way down here\n",
    "# going to move this higher\n",
    "# def tree_explain_good(idx):\n",
    "#     pred, bias, contrib = ti.predict(tmodel, vgood2ref[idx, :].reshape((1, -1)))\n",
    "#     print('CLEAN TEXT: ', vax_good_df.iloc[idx].cleanText)\n",
    "#     cmat = contrib.reshape((-1, 2))\n",
    "#     print('Prediction: ', pred)\n",
    "#     print('Bias: ', bias)\n",
    "#     import_bad = np.argsort(cmat[:, 0])[::-1]\n",
    "#     import_good = np.argsort(cmat[:, 1])[::-1]\n",
    "#     print('===== Towards Good: =====')\n",
    "#     for idx in import_good[:5]:\n",
    "#         print('-'*45)\n",
    "#         print(f'CONTRIB: {cmat[idx]}')\n",
    "#         print(f'ABSTRACT: {has_vax.iloc[idx].abstract}')\n",
    "#         print(f'TITLE: {has_vax.iloc[idx].title}')\n",
    "#     print('===== Towards Bad: =====')\n",
    "#     for idx in import_bad[:5]:\n",
    "#         print('-'*45)\n",
    "#         print(f'CONTRIB: {cmat[idx]}')\n",
    "#         print(f'ABSTRACT: {has_vax.iloc[idx].abstract}')\n",
    "#         print(f'TITLE: {has_vax.iloc[idx].title}')\n",
    "\n",
    "# def tree_explain_bad(idx):\n",
    "#     pred, bias, contrib = ti.predict(tmodel, vbad2ref[idx, :].reshape((1, -1)))\n",
    "#     print('CLEAN TEXT: ', vax_bad_df.iloc[idx].cleanText)\n",
    "#     cmat = contrib.reshape((-1, 2))\n",
    "#     print('Prediction: ', pred)\n",
    "#     print('Bias: ', bias)\n",
    "#     import_bad = np.argsort(cmat[:, 0])[::-1]\n",
    "#     import_good = np.argsort(cmat[:, 1])[::-1]\n",
    "#     print('===== Towards Bad: =====')\n",
    "#     for idx in import_bad[:5]:\n",
    "#         print('-'*45)\n",
    "#         print(f'CONTRIB: {cmat[idx]}')\n",
    "#         print(f'ABSTRACT: {has_vax.iloc[idx].abstract}')\n",
    "#         print(f'TITLE: {has_vax.iloc[idx].title}')\n",
    "#     print('===== Towards Good: =====')\n",
    "#     for idx in import_good[:5]:\n",
    "#         print('-'*45)\n",
    "#         print(f'CONTRIB: {cmat[idx]}')\n",
    "#         print(f'ABSTRACT: {has_vax.iloc[idx].abstract}')\n",
    "#         print(f'TITLE: {has_vax.iloc[idx].title}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, bias, contrib = ti.predict(tmodel, vbad2ref[290, :].reshape((1, -1)))\n",
    "# pred, bias, contrib = ti.predict(tmodel, vbad2ref[290, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmat = contrib.reshape((-1, 2))\n",
    "import_bad = np.argsort(cmat[:, 0])[::-1]\n",
    "import_good = np.argsort(cmat[:, 1])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claims_df = load_pickle('./pickles/newest_claims_df_labelled.pkl')\n",
    "# claims_df = claims_df.dropna()\n",
    "\n",
    "# true_claims_df = claims_df[claims_df['label'] == 'true']\n",
    "# false_claims_df = claims_df[claims_df['label'] == 'false']\n",
    "# misleading_claims_df = claims_df[claims_df['label'] == 'misleading']\n",
    "\n",
    "# true_claims_mat = np.vstack(list(true_claims_df['bert_embedding']))\n",
    "# false_claims_mat = np.vstack(list(false_claims_df['bert_embedding']))\n",
    "\n",
    "# true_claims2ref = cdist(true_claims_mat, vax_ref, 'cosine')\n",
    "# false_claims2ref = cdist(false_claims_mat, vax_ref, 'cosine')\n",
    "\n",
    "# claims_mm = MarkedMatrix([('true', true_claims_mat), ('false', false_claims_mat)])\n",
    "# claims_mm2covid = MarkedMatrix([('true', true_claims2ref), ('false', false_claims2ref)])\n",
    "# claims_mm.single_split_classify(tmodel, return_labels=True)\n",
    "# tmodel_claims = RandomForestClassifier(n_estimators=500, n_jobs=24)\n",
    "# claims_mm2covid.single_split_classify(tmodel_claims, return_labels=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
